{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef355cd2-80a9-489c-b423-af7bef3c432a",
   "metadata": {},
   "source": [
    "# 通义模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cee054d-5a2d-426f-b4de-4f46eb132fec",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-09-21T07:21:35.245239Z",
     "iopub.status.busy": "2024-09-21T07:21:35.245068Z",
     "iopub.status.idle": "2024-09-21T07:21:38.399910Z",
     "shell.execute_reply": "2024-09-21T07:21:38.399319Z",
     "shell.execute_reply.started": "2024-09-21T07:21:35.245217Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from modelscope import AutoModelForCausalLM,AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def create_qwen_model():\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"qwen/Qwen2-0.5B-Instruct\",\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"qwen/Qwen2-0.5B-Instruct\")\n",
    "    return model,tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e12a94c0-fdd0-41af-8078-091d5d356846",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-09-21T07:21:38.401730Z",
     "iopub.status.busy": "2024-09-21T07:21:38.401361Z",
     "iopub.status.idle": "2024-09-21T07:21:43.484513Z",
     "shell.execute_reply": "2024-09-21T07:21:43.483933Z",
     "shell.execute_reply.started": "2024-09-21T07:21:38.401707Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DPO训练的模型\n",
    "model_pi,tokenizer=create_qwen_model()\n",
    "# DPO参照的模型\n",
    "model_ref,_=create_qwen_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df98393b-9a1b-4833-8c4f-8cb2ab2cec18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T07:21:43.485608Z",
     "iopub.status.busy": "2024-09-21T07:21:43.485374Z",
     "iopub.status.idle": "2024-09-21T07:21:43.490248Z",
     "shell.execute_reply": "2024-09-21T07:21:43.489696Z",
     "shell.execute_reply.started": "2024-09-21T07:21:43.485586Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型测试方法\n",
    "def chat(prompt,tokenizer,model):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    #print(text)\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=512\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f16dc6-3233-4db4-a8dc-a211a8eb76ca",
   "metadata": {},
   "source": [
    "# 训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7850992b-7084-4746-a273-2571164760d9",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-09-21T07:21:43.491416Z",
     "iopub.status.busy": "2024-09-21T07:21:43.491048Z",
     "iopub.status.idle": "2024-09-21T07:21:43.496137Z",
     "shell.execute_reply": "2024-09-21T07:21:43.495617Z",
     "shell.execute_reply.started": "2024-09-21T07:21:43.491395Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dpo_train_data=[\n",
    "    {'prompt':'你是谁?','chosen':'通义千问','reject':'我是阿里云开发的超大规模语言模型，我叫通义千问。'},\n",
    "    {'prompt':'你是谁发明的?','chosen':'小鱼儿','reject':'阿里巴巴'},\n",
    "]\n",
    "\n",
    "# 偏好数据集 -> 模型输入\n",
    "def dpo_to_messages(dpo_pairs):\n",
    "    chosen_messages=[]\n",
    "    reject_messages=[]\n",
    "    for pair in dpo_pairs:\n",
    "        chosen_messages.append([\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": pair['prompt']},\n",
    "                {\"role\": \"assistant\", \"content\": pair['chosen']},\n",
    "            ]\n",
    "        )\n",
    "        reject_messages.append([\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": pair['prompt']},\n",
    "                {\"role\": \"assistant\", \"content\": pair['reject']},\n",
    "            ]\n",
    "        )\n",
    "    return chosen_messages,reject_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88a49d8-e64a-469a-9d9f-97414107ce55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T07:21:43.497046Z",
     "iopub.status.busy": "2024-09-21T07:21:43.496863Z",
     "iopub.status.idle": "2024-09-21T07:21:43.503604Z",
     "shell.execute_reply": "2024-09-21T07:21:43.503085Z",
     "shell.execute_reply.started": "2024-09-21T07:21:43.497027Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练数据预处理\n",
    "def preprocess(tokenizer,batch_messages):\n",
    "    input_list=[]\n",
    "    target_list=[]\n",
    "    \n",
    "    im_start=tokenizer('<|im_start|>').input_ids\n",
    "    im_end=tokenizer('<|im_end|>').input_ids\n",
    "    newline=tokenizer('\\n').input_ids\n",
    "    pad=tokenizer('<|endoftext|>').input_ids\n",
    "    ignore=[-100]\n",
    "    \n",
    "    for group in batch_messages:\n",
    "        input_ids=[]\n",
    "        target_ids=[]\n",
    "        for msg in group:\n",
    "            role=tokenizer(msg['role']).input_ids\n",
    "            content=tokenizer(msg['content']).input_ids\n",
    "            if msg['role'] in ['system','user']:\n",
    "                ignore_parts=role+newline+content\n",
    "                input_ids+=im_start+ignore_parts+im_end+newline\n",
    "                target_ids+=im_start+ignore*len(ignore_parts)+im_end+newline\n",
    "            else:\n",
    "                ignore_parts=role+newline\n",
    "                input_ids+=im_start+ignore_parts+content+im_end+newline\n",
    "                target_ids+=im_start+ignore*len(ignore_parts)+content+im_end+newline\n",
    "        input_list.append(input_ids)\n",
    "        target_list.append(target_ids)\n",
    "    \n",
    "    # padding\n",
    "    max_len=max([len(ids) for ids in input_list])\n",
    "    for input_ids,target_ids in zip(input_list,target_list):\n",
    "        input_ids+=pad*(max_len-len(input_ids))\n",
    "        target_ids+=ignore*(max_len-len(target_ids))\n",
    "    batch_input_ids=torch.tensor(input_list,dtype=torch.long)\n",
    "    batch_target_ids=torch.tensor(target_list,dtype=torch.long)\n",
    "    batch_mask=batch_input_ids.ne(pad[0]).type(torch.long)\n",
    "    return batch_input_ids,batch_target_ids,batch_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa2c1d5-dc25-4fbf-8ae5-fcb2f565a7dd",
   "metadata": {},
   "source": [
    "# DPO训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5222f54-0e3a-49d4-9e28-921ca6ce6f38",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-09-21T07:21:43.504797Z",
     "iopub.status.busy": "2024-09-21T07:21:43.504423Z",
     "iopub.status.idle": "2024-09-21T07:21:43.513992Z",
     "shell.execute_reply": "2024-09-21T07:21:43.513544Z",
     "shell.execute_reply.started": "2024-09-21T07:21:43.504776Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pi.train()\n",
    "model_ref.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ee1a21-5b4e-4342-a8ee-1385b3f4e392",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-09-21T07:21:43.515828Z",
     "iopub.status.busy": "2024-09-21T07:21:43.515491Z",
     "iopub.status.idle": "2024-09-21T07:21:43.519616Z",
     "shell.execute_reply": "2024-09-21T07:21:43.519069Z",
     "shell.execute_reply.started": "2024-09-21T07:21:43.515808Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 优化器，只训练pi模型\n",
    "optimizer=torch.optim.SGD(model_pi.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87dac537-5bb4-425c-a240-ac685c83291d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-09-21T07:22:15.967827Z",
     "iopub.status.busy": "2024-09-21T07:22:15.967449Z",
     "iopub.status.idle": "2024-09-21T07:22:15.974971Z",
     "shell.execute_reply": "2024-09-21T07:22:15.974404Z",
     "shell.execute_reply.started": "2024-09-21T07:22:15.967804Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DPO损失计算-辅助函数\n",
    "def dpo_prob_calc(target_ids,pi_logits,ref_logits):\n",
    "    pi_probs=torch.log_softmax(pi_logits,dim=-1)      # softmax概率+log对数\n",
    "    ref_probs=torch.log_softmax(ref_logits,dim=-1)\n",
    "    \n",
    "    ignore_mask=target_ids!=-100 # ignore token掩码\n",
    "    indexes=target_ids*ignore_mask # 将-100变成0，以便后面gather可以运行\n",
    "    \n",
    "    pi_probs_of_target=torch.gather(pi_probs,dim=-1,index=indexes.unsqueeze(-1)).squeeze(-1) * ignore_mask # 取目标target token的概率，忽略-100 token\n",
    "    ref_probs_of_target=torch.gather(ref_probs,dim=-1,index=indexes.unsqueeze(-1)).squeeze(-1) * ignore_mask    \n",
    "    \n",
    "    pi_final_prob=pi_probs_of_target.sum(-1)/ignore_mask.sum(-1)     # 求每一个样本的token prob均值\n",
    "    ref_final_prob=ref_probs_of_target.sum(-1)/ignore_mask.sum(-1)\n",
    "    return pi_final_prob,ref_final_prob\n",
    "    \n",
    "# DPO损失函数 https://github.com/huggingface/trl/blob/main/trl/trainer/dpo_trainer.py\n",
    "def dpo_loss(params):\n",
    "    ## 两个模型的chosen输出\n",
    "    chosen_target_ids=params['chosen_target_ids'][:,1:]\n",
    "    pi_chosen_logits=params['pi_chosen_logits'][:,:-1,:]\n",
    "    ref_chosen_logits=params['ref_chosen_logits'][:,:-1,:]\n",
    "    pi_chosen_prob,ref_chosen_prob=dpo_prob_calc(chosen_target_ids,pi_chosen_logits,ref_chosen_logits)\n",
    "    \n",
    "    ## 两个模型的reject输出\n",
    "    reject_target_ids=params['reject_target_ids'][:,1:]\n",
    "    pi_reject_logits=params['pi_reject_logits'][:,:-1,:]\n",
    "    ref_reject_logits=params['ref_reject_logits'][:,:-1,:]\n",
    "    pi_reject_prob,ref_reject_prob=dpo_prob_calc(reject_target_ids,pi_reject_logits,ref_reject_logits)\n",
    "    \n",
    "    # 计算DPO Loss\n",
    "    pi_prob_diff=pi_chosen_prob-pi_reject_prob \n",
    "    ref_prob_diff=ref_chosen_prob-ref_reject_prob\n",
    "    beta=0.1\n",
    "    loss=-torch.nn.functional.logsigmoid(beta*(pi_prob_diff-ref_prob_diff))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5de8e708-ce5f-4c80-82f6-989285a7f284",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-09-21T07:22:32.754051Z",
     "iopub.status.busy": "2024-09-21T07:22:32.753678Z",
     "iopub.status.idle": "2024-09-21T07:22:35.305485Z",
     "shell.execute_reply": "2024-09-21T07:22:35.304798Z",
     "shell.execute_reply.started": "2024-09-21T07:22:32.754027Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2781, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "iterators=20\n",
    "\n",
    "vocab=tokenizer.get_vocab()\n",
    "for i in range(iterators):\n",
    "    # 一批模拟数据\n",
    "    chosen_messages,reject_messages=dpo_to_messages(dpo_train_data)\n",
    "    # model输入和输出\n",
    "    chosen_input_ids,chosen_target_ids,chosen_mask=preprocess(tokenizer,chosen_messages)\n",
    "    reject_input_ids,reject_target_ids,reject_mask=preprocess(tokenizer,reject_messages)\n",
    "    # model_pi预测\n",
    "    pi_chosen_logits=model_pi(input_ids=chosen_input_ids.to(device),attention_mask=chosen_mask.to(device)).logits\n",
    "    pi_reject_logits=model_pi(input_ids=reject_input_ids.to(device),attention_mask=reject_mask.to(device)).logits\n",
    "    # model_ref预测\n",
    "    ref_chosen_logits=model_ref(chosen_input_ids.to(device),chosen_mask.to(device)).logits\n",
    "    ref_reject_logits=model_ref(reject_input_ids.to(device),reject_mask.to(device)).logits\n",
    "    # 求DPO损失\n",
    "    loss=dpo_loss({\n",
    "        'chosen_target_ids':chosen_target_ids.to(device),\n",
    "        'reject_target_ids':reject_target_ids.to(device),\n",
    "        'pi_chosen_logits':pi_chosen_logits.to(device),\n",
    "        'pi_reject_logits':pi_reject_logits.to(device),\n",
    "        'ref_chosen_logits':ref_chosen_logits.to(device),\n",
    "        'ref_reject_logits':ref_reject_logits.to(device),\n",
    "    })\n",
    "    print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7061db38-7d78-4d11-803d-4dff4f98a19f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-09-21T07:22:36.589519Z",
     "iopub.status.busy": "2024-09-21T07:22:36.589165Z",
     "iopub.status.idle": "2024-09-21T07:22:36.696237Z",
     "shell.execute_reply": "2024-09-21T07:22:36.695668Z",
     "shell.execute_reply.started": "2024-09-21T07:22:36.589495Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'通义千问'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat('你是谁?',tokenizer,model_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f3c7feb-350d-4208-9ab5-75186339a031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-21T07:22:47.938062Z",
     "iopub.status.busy": "2024-09-21T07:22:47.937705Z",
     "iopub.status.idle": "2024-09-21T07:22:48.024236Z",
     "shell.execute_reply": "2024-09-21T07:22:48.023733Z",
     "shell.execute_reply.started": "2024-09-21T07:22:47.938039Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'小鱼儿'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat('你是谁发明的?',tokenizer,model_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e848068-aa49-4a0d-b116-ebe34ed8c9d2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-09-21T07:22:50.179585Z",
     "iopub.status.busy": "2024-09-21T07:22:50.179040Z",
     "iopub.status.idle": "2024-09-21T07:22:53.335017Z",
     "shell.execute_reply": "2024-09-21T07:22:53.334491Z",
     "shell.execute_reply.started": "2024-09-21T07:22:50.179560Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformer模型是一种用于处理语言模型的深度学习框架，它由一系列的层组成，每个层都有一个输入和一个输出。这个模型主要用于生成具有特定语义关系的语言模型。\\n\\n具体来说，Transformer模型通常包括两个主要部分：一个编码器（Encoder）和一个解码器（Decoder）。在Encoder中，输入被映射到一系列的隐藏单元（Hidden Layers），这些隐藏单元可以分别代表句子或段落中的词语；而在Decoder中，这些隐藏单元被用来将输入转换成一个与原始输入有相似语义的关系的输出。\\n\\nTransformer模型的优点在于它可以自动从大量数据中提取模式，从而实现大规模语言模型的训练。此外，它还可以根据新的输入来调整其参数，以适应不同的应用场景。'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat('讲讲transformer模型',tokenizer,model_pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
